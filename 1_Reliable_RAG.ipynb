{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAIj6QBW5REQ"
      },
      "source": [
        "## Reliable-RAG 🏷️\n",
        "\n",
        "*   Reference: https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb\n",
        "*   Updated by: Wilfredo Aaron Sosa Ramos\n",
        "\n",
        "### Overview\n",
        "\n",
        "The \"Reliable-RAG\" method enhances the traditional Retrieval-Augmented Generation (RAG) approach by adding layers of validation and refinement to ensure the accuracy and relevance of retrieved information. This system is designed to process and query web-based documents, encode their content into a vector store, and retrieve the most relevant segments for generating precise and reliable answers. The method incorporates checks for document relevancy, hallucination prevention, and highlights the exact segments used in generating the final response.\n",
        "\n",
        "### Key Components\n",
        "\n",
        "1. **Document Loading and Chunking:**\n",
        "   - Web-based documents are loaded and split into smaller, manageable chunks to facilitate efficient vector encoding and retrieval.\n",
        "\n",
        "2. **Vectorstore Creation:**\n",
        "   - Utilizes Chroma and Cohere embeddings to encode document chunks into a vector store, enabling efficient similarity-based retrieval.\n",
        "\n",
        "3. **Document Relevancy Check:**\n",
        "   - Implements a relevance-checking mechanism using a language model to filter out non-relevant documents before answer generation.\n",
        "\n",
        "4. **Answer Generation:**\n",
        "   - Employs a language model to generate concise answers based on the relevant documents retrieved.\n",
        "\n",
        "5. **Hallucination Detection:**\n",
        "   - A dedicated hallucination detection step ensures that the generated answers are grounded in the retrieved documents, preventing the inclusion of unsupported or erroneous information.\n",
        "\n",
        "6. **Document Snippet Highlighting:**\n",
        "   - The system identifies and highlights the specific document segments that were directly used to generate the answer, providing transparency and traceability.\n",
        "\n",
        "### Motivation\n",
        "\n",
        "The Reliable-RAG method was developed to address the common challenges faced in traditional RAG systems, such as retrieving irrelevant documents, generating answers that are not grounded in facts, and the lack of transparency in the sources used for answer generation. By adding multiple layers of validation, this method ensures that the answers provided are both accurate and reliable.\n",
        "\n",
        "### Method Details and Benefits\n",
        "\n",
        "- **Document Relevancy Filtering:**\n",
        "  By using a binary relevancy score generated by a language model, only the most relevant documents are passed on to the answer generation phase, reducing noise and improving the quality of the final answer.\n",
        "\n",
        "- **Hallucination Check:**\n",
        "  Before finalizing the answer, the system checks for hallucinations by verifying that the generated content is fully supported by the retrieved documents.\n",
        "\n",
        "- **Snippet Highlighting:**\n",
        "  This feature enhances transparency by showing the exact segments from the retrieved documents that contributed to the final answer.\n",
        "\n",
        "## Implementation\n",
        "\n",
        "### Step-by-Step Python Implementation\n",
        "\n",
        "1. **Import Libraries and Set Environment Variables**\n",
        "   - Import necessary libraries and set environment variables for LLM and embedding model access.\n",
        "\n",
        "2. **Create Vectorstore**\n",
        "   - Load web-based documents, split them into chunks, and create a vector store using Chroma and Cohere embeddings.\n",
        "\n",
        "3. **Question Query**\n",
        "   - Define the user query and retrieve the top relevant documents from the vector store.\n",
        "\n",
        "4. **Check Document Relevancy**\n",
        "   - Filter out non-relevant documents using a binary relevancy score provided by a language model.\n",
        "\n",
        "5. **Generate Answer**\n",
        "   - Use the relevant documents to generate a concise answer to the user query.\n",
        "\n",
        "6. **Check for Hallucinations**\n",
        "   - Ensure that the generated answer is fully grounded in the retrieved documents.\n",
        "\n",
        "7. **Highlight Document Snippets**\n",
        "   - Identify and highlight the exact segments from the retrieved documents that were used to generate the final answer.\n",
        "\n",
        "### Additional Considerations\n",
        "\n",
        "- **Limitations:** The system's performance is dependent on the quality of the embeddings and the effectiveness of the hallucination detection mechanism.\n",
        "- **Potential Improvements:** Incorporating more sophisticated models for relevancy checking and hallucination detection could further enhance the system's reliability.\n",
        "- **Specific Use Cases:** This method is particularly useful in domains where factual accuracy and transparency are paramount, such as legal or academic research."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain_core langchain_community langgraph langchain_cohere langchain_groq chroma langchain_chroma tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWD630FQAE4U",
        "outputId": "824eb4b1-8454-4ad5-90bf-41b347838d88"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3wBJAx75REY"
      },
      "source": [
        "###  Import Libraries and enviornment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sr9pAVAz5REZ"
      },
      "outputs": [],
      "source": [
        "### LLMs\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY') # For LLM -- llama-3.1-8b (small) & mixtral-8x7b-32768 (large)\n",
        "os.environ['COHERE_API_KEY'] = userdata.get('COHERE_API_KEY') # For embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnoeOhs95REa"
      },
      "source": [
        "### Create Vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wJj8XMcV5REb"
      },
      "outputs": [],
      "source": [
        "### Build Index\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_cohere import CohereEmbeddings\n",
        "\n",
        "# Set embeddings\n",
        "embedding_model = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
        "\n",
        "# Docs to index\n",
        "urls = [\n",
        "    \"https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\",\n",
        "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io\",\n",
        "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io\",\n",
        "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io\",\n",
        "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io\"\n",
        "]\n",
        "\n",
        "def return_retriever(urls):\n",
        "  # Load\n",
        "  docs = [WebBaseLoader(url).load() for url in urls]\n",
        "  docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "  # Split\n",
        "  text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "      chunk_size=500, chunk_overlap=0\n",
        "  )\n",
        "  doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "  print(\"Generating Vector Store with Cohere and URLs\")\n",
        "\n",
        "  # Add to vectorstore\n",
        "  vectorstore = Chroma.from_documents(\n",
        "      documents=doc_splits,\n",
        "      collection_name=\"rag\",\n",
        "      embedding=embedding_model,\n",
        "  )\n",
        "\n",
        "  print(\"Vector Store successfully generated\")\n",
        "  print(\"Generating retriever\")\n",
        "\n",
        "  retriever = vectorstore.as_retriever(\n",
        "                  search_type=\"similarity\",\n",
        "                  search_kwargs={'k': 4}, # number of documents to retrieve\n",
        "              )\n",
        "\n",
        "  print(\"Retriever successfully generated\")\n",
        "\n",
        "  return retriever"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = return_retriever(urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWOg7AB9F6x4",
        "outputId": "8cb68e15-4ce5-422f-f086-4194f1206911"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Vector Store with Cohere and URLs\n",
            "Vector Store successfully generated\n",
            "Generating retriever\n",
            "Retriever successfully generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IShM6U-j5REe"
      },
      "source": [
        "### Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Te_JmJOx5REg"
      },
      "outputs": [],
      "source": [
        "question = \"what are the differnt kind of agentic design patterns?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJe8-8BV5REh"
      },
      "source": [
        "### Retrieve docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lcO2wR3Q5REi"
      },
      "outputs": [],
      "source": [
        "docs = retriever.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWJoE0EAG9nr",
        "outputId": "e73a7884-e7a6-404a-e9e8-3a2146aed78b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'description': 'I think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io', 'title': 'Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance'}, page_content='is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.\\xa0Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it.\\xa0Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout'),\n",
              " Document(metadata={'description': 'Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I’ve described in recent letters...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 5, Multi-Agent Collaboration'}, page_content=\"Agentic Design Patterns Part 5, Multi-Agent Collaboration✨ New course! Enroll in Reasoning with o1Explore CoursesAI NewsletterThe BatchAndrew's LetterData PointsML ResearchBlogCommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew's LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 5, Multi-Agent Collaboration Prompting an LLM to play different roles for different parts of a complex task summons a team of AI agents that can do the job more effectively.LettersTechnical InsightsPublishedApr 17, 2024Reading time3 min readShareDear friends,Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I’ve described in recent letters. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles — such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on — and have different agents accomplish different subtasks.Different agents might be built by prompting one LLM (or, if you prefer, multiple LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: “You are an expert in writing clear, efficient code. Write code to perform the task . . ..”\\xa0It might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I’d like to offer a few reasons:It works! Many teams are getting good results with this method, and there’s nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent.\\xa0Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that role’s subtask. For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable\"),\n",
              " Document(metadata={'description': 'Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I’ve described in recent letters...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 5, Multi-Agent Collaboration'}, page_content='and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.In many companies, managers routinely decide what roles to hire, and then how to split complex projects — like writing a large piece of software or preparing a research report — into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows.\\xa0While managing people is hard, it\\'s a sufficiently familiar idea that it gives us a mental framework for how to \"hire\" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans!\\xa0Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you\\'re interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their\\xa0GitHub repo\\xa0and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does.\\xa0Like the design pattern of\\xa0Planning, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of\\xa0Reflection\\xa0and\\xa0Tool Use\\xa0are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you!\\xa0If you\\'re interested in learning more, I'),\n",
              " Document(metadata={'description': 'Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 3: Tool Use'}, page_content='(2023)“MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,” Yang et al. (2023)“Efficient Tool Use with Chain-of-Abstraction Reasoning,” Gao et al. (2024)\\xa0 \\xa0Both Tool Use and Reflection, which I described in last week’s\\xa0letter, are design patterns that I can get to work fairly reliably on my applications — both are capabilities well worth learning about. In future letters, I’ll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable — albeit very exciting — technologies.\\xa0Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z9--jFE5REj"
      },
      "source": [
        "### Check what our doc looklike"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4aQqPi95REj",
        "outputId": "117439a5-0fec-4c16-a3bd-3a07c528c8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance\n",
            "\n",
            "Source: https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\n",
            "\n",
            "Content: is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%. Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it. Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Title: {docs[0].metadata['title']}\\n\\nSource: {docs[0].metadata['source']}\\n\\nContent: {docs[0].page_content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPjUR-Gk5REl"
      },
      "source": [
        "### Check document relevancy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "stgJaX8J5REl"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_groq import ChatGroq\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Data model\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "def filter_doc(question, doc, retrieval_grader):\n",
        "    \"\"\"Function to grade a single document for relevance.\"\"\"\n",
        "    print(doc.page_content, '\\n', '-'*50)\n",
        "    res = retrieval_grader.invoke({\"question\": question, \"document\": doc.page_content})\n",
        "    print(res, '\\n')\n",
        "    return doc if res.binary_score == 'yes' else None\n",
        "\n",
        "def filter_non_relevant_docs(question):\n",
        "    docs = retriever.invoke(question)\n",
        "    # LLM with function call\n",
        "    llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
        "    structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "    # Prompt\n",
        "    system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
        "    grade_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    retrieval_grader = grade_prompt | structured_llm_grader\n",
        "\n",
        "    docs_to_use = []\n",
        "\n",
        "    # Use ThreadPoolExecutor for multithreading\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        # Map each document to the grading function\n",
        "        results = list(executor.map(lambda doc: filter_doc(question, doc, retrieval_grader), docs))\n",
        "\n",
        "    # Filter out None values (non-relevant documents)\n",
        "    docs_to_use = [doc for doc in results if doc is not None]\n",
        "\n",
        "    return docs_to_use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtV_5KDi5REm"
      },
      "source": [
        "### Filter out the non-relevant docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jduOBLkB5REm",
        "outputId": "c02418d6-814c-47f2-b47b-00ad9dd73d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%. Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it. Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout \n",
            " --------------------------------------------------\n",
            "Agentic Design Patterns Part 5, Multi-Agent Collaboration✨ New course! Enroll in Reasoning with o1Explore CoursesAI NewsletterThe BatchAndrew's LetterData PointsML ResearchBlogCommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew's LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 5, Multi-Agent Collaboration Prompting an LLM to play different roles for different parts of a complex task summons a team of AI agents that can do the job more effectively.LettersTechnical InsightsPublishedApr 17, 2024Reading time3 min readShareDear friends,Multi-agent collaboration is the last of the four key AI agentic design patterns that I’ve described in recent letters. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles — such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on — and have different agents accomplish different subtasks.Different agents might be built by prompting one LLM (or, if you prefer, multiple LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: “You are an expert in writing clear, efficient code. Write code to perform the task . . ..” It might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I’d like to offer a few reasons:It works! Many teams are getting good results with this method, and there’s nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent. Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that role’s subtask. For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable \n",
            " --------------------------------------------------\n",
            "and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.In many companies, managers routinely decide what roles to hire, and then how to split complex projects — like writing a large piece of software or preparing a research report — into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows. While managing people is hard, it's a sufficiently familiar idea that it gives us a mental framework for how to \"hire\" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans! Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you're interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their GitHub repo and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does. Like the design pattern of Planning, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of Reflection and Tool Use are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you! If you're interested in learning more, I \n",
            " --------------------------------------------------\n",
            "(2023)“MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,” Yang et al. (2023)“Efficient Tool Use with Chain-of-Abstraction Reasoning,” Gao et al. (2024)   Both Tool Use and Reflection, which I described in last week’s letter, are design patterns that I can get to work fairly reliably on my applications — both are capabilities well worth learning about. In future letters, I’ll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable — albeit very exciting — technologies. Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout \n",
            " --------------------------------------------------\n",
            "binary_score='yes'binary_score='yes' \n",
            "\n",
            " \n",
            "\n",
            "binary_score='yes' \n",
            "\n",
            "binary_score='yes' \n",
            "\n"
          ]
        }
      ],
      "source": [
        "docs_to_use = filter_non_relevant_docs(question)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_to_use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eghs5nVyJ5ql",
        "outputId": "ed467ffd-0e84-4e1f-f909-94bdc8ee68bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'description': 'I think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io', 'title': 'Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance'}, page_content='is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.\\xa0Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it.\\xa0Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout'),\n",
              " Document(metadata={'description': 'Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I’ve described in recent letters...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 5, Multi-Agent Collaboration'}, page_content=\"Agentic Design Patterns Part 5, Multi-Agent Collaboration✨ New course! Enroll in Reasoning with o1Explore CoursesAI NewsletterThe BatchAndrew's LetterData PointsML ResearchBlogCommunityForumEventsAmbassadorsAmbassador SpotlightResourcesCompanyAboutCareersContactStart LearningWeekly IssuesAndrew's LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 5, Multi-Agent Collaboration Prompting an LLM to play different roles for different parts of a complex task summons a team of AI agents that can do the job more effectively.LettersTechnical InsightsPublishedApr 17, 2024Reading time3 min readShareDear friends,Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I’ve described in recent letters. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles — such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on — and have different agents accomplish different subtasks.Different agents might be built by prompting one LLM (or, if you prefer, multiple LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: “You are an expert in writing clear, efficient code. Write code to perform the task . . ..”\\xa0It might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I’d like to offer a few reasons:It works! Many teams are getting good results with this method, and there’s nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent.\\xa0Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that role’s subtask. For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable\"),\n",
              " Document(metadata={'description': 'Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I’ve described in recent letters...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 5, Multi-Agent Collaboration'}, page_content='and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.In many companies, managers routinely decide what roles to hire, and then how to split complex projects — like writing a large piece of software or preparing a research report — into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows.\\xa0While managing people is hard, it\\'s a sufficiently familiar idea that it gives us a mental framework for how to \"hire\" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans!\\xa0Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you\\'re interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their\\xa0GitHub repo\\xa0and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does.\\xa0Like the design pattern of\\xa0Planning, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of\\xa0Reflection\\xa0and\\xa0Tool Use\\xa0are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you!\\xa0If you\\'re interested in learning more, I'),\n",
              " Document(metadata={'description': 'Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design...', 'language': 'en', 'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 3: Tool Use'}, page_content='(2023)“MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,” Yang et al. (2023)“Efficient Tool Use with Chain-of-Abstraction Reasoning,” Gao et al. (2024)\\xa0 \\xa0Both Tool Use and Reflection, which I described in last week’s\\xa0letter, are design patterns that I can get to work fairly reliably on my applications — both are capabilities well worth learning about. In future letters, I’ll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable — albeit very exciting — technologies.\\xa0Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhy0vXpi5REn"
      },
      "source": [
        "### Generate Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S7nRS99n5REn"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def format_docs(docs):\n",
        "      return \"\\n\".join(f\"<doc{i+1}>:\\nTitle:{doc.metadata['title']}\\nSource:{doc.metadata['source']}\\nContent:{doc.page_content}\\n</doc{i+1}>\\n\" for i, doc in enumerate(docs))\n",
        "\n",
        "def generate_result(docs_to_use, question):\n",
        "  # Prompt\n",
        "  system = \"\"\"You are an assistant for question-answering tasks. Answer the question based upon your knowledge.\n",
        "  Use three-to-five sentences maximum and keep the answer concise.\"\"\"\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\"system\", system),\n",
        "          (\"human\", \"Retrieved documents: \\n\\n <docs>{documents}</docs> \\n\\n User question: <question>{question}</question>\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # LLM\n",
        "  llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
        "\n",
        "  # Chain\n",
        "  rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "  # Run\n",
        "  generation = rag_chain.invoke({\"documents\":format_docs(docs_to_use), \"question\": question})\n",
        "  return generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation = generate_result(docs_to_use, question)"
      ],
      "metadata": {
        "id": "5gnF_MwHKp5S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO-zCZEPKyxB",
        "outputId": "eb61b4f6-326f-496d-9b11-8d2da5d372fd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the retrieved documents, there are four key AI agentic design patterns described by Andrew: \n",
            "\n",
            "1. Reflection: The LLM examines its own work to come up with ways to improve it.\n",
            "2. Tool Use: The LLM is given tools to help it gather information, take action, or process data.\n",
            "3. Planning: The LLM comes up with and executes a multistep plan to achieve a goal.\n",
            "4. Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPA8MpvJ5REn"
      },
      "source": [
        "### Check for Hallucinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Iyruy7G45REn"
      },
      "outputs": [],
      "source": [
        "# Data model\n",
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Binary score for hallucination present in 'generation' answer.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        ...,\n",
        "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "def check_for_hallucinations(generation, docs_to_use):\n",
        "\n",
        "  # LLM with function call\n",
        "  llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
        "  structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
        "\n",
        "  # Prompt\n",
        "  system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
        "      Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
        "  hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\"system\", system),\n",
        "          (\"human\", \"Set of facts: \\n\\n <facts>{documents}</facts> \\n\\n LLM generation: <generation>{generation}</generation>\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  hallucination_grader = hallucination_prompt | structured_llm_grader\n",
        "\n",
        "  response = hallucination_grader.invoke({\"documents\": format_docs(docs_to_use), \"generation\": generation})\n",
        "\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = check_for_hallucinations(generation, docs_to_use)"
      ],
      "metadata": {
        "id": "Nnf1gtuYL1dh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJylFIIALtA1",
        "outputId": "98077da3-f2d2-410e-fb63-7cdc1eae3974"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjRpp_KW5REo"
      },
      "source": [
        "### Highlight used docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TWnTnE2K5REo"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Data model\n",
        "class HighlightDocuments(BaseModel):\n",
        "    \"\"\"Return the specific part of a document used for answering the question.\"\"\"\n",
        "\n",
        "    id: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of id of docs used to answers the question\"\n",
        "    )\n",
        "\n",
        "    title: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of titles used to answers the question\"\n",
        "    )\n",
        "\n",
        "    source: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of sources used to answers the question\"\n",
        "    )\n",
        "\n",
        "    segment: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"List of direct segements from used documents that answers the question\"\n",
        "    )\n",
        "\n",
        "def highlight_docs(question, generation, docs_to_use):\n",
        "  # LLM\n",
        "  llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
        "\n",
        "  # parser\n",
        "  parser = JsonOutputParser(pydantic_object=HighlightDocuments)\n",
        "\n",
        "  # Prompt\n",
        "  system = \"\"\"You are an advanced assistant for document search and retrieval. You are provided with the following:\n",
        "  1. A question.\n",
        "  2. A generated answer based on the question.\n",
        "  3. A set of documents that were referenced in generating the answer.\n",
        "\n",
        "  Your task is to identify and extract the exact inline segments from the provided documents that directly correspond to the content used to\n",
        "  generate the given answer. The extracted segments must be verbatim snippets from the documents, ensuring a word-for-word match with the text\n",
        "  in the provided documents.\n",
        "\n",
        "  Ensure that:\n",
        "  - (Important) Each segment is an exact match to a part of the document and is fully contained within the document text.\n",
        "  - The relevance of each segment to the generated answer is clear and directly supports the answer provided.\n",
        "  - (Important) If you didn't used the specific document don't mention it.\n",
        "\n",
        "  Used documents: <docs>{documents}</docs> \\n\\n User question: <question>{question}</question> \\n\\n Generated answer: <answer>{generation}</answer>\n",
        "\n",
        "  You must respond as a JSON format:\n",
        "\n",
        "  <format_instruction>\n",
        "  {format_instructions}\n",
        "  </format_instruction>\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  prompt = PromptTemplate(\n",
        "      template= system,\n",
        "      input_variables=[\"documents\", \"question\", \"generation\"],\n",
        "      partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "  )\n",
        "\n",
        "  # Chain\n",
        "  doc_lookup = prompt | llm | parser\n",
        "\n",
        "  # Run\n",
        "  lookup_response = doc_lookup.invoke({\"documents\":format_docs(docs_to_use), \"question\": question, \"generation\": generation})\n",
        "\n",
        "  return lookup_response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_response = highlight_docs(question, generation, docs_to_use)"
      ],
      "metadata": {
        "id": "faVvMF_7O5kp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgQO5qIjQHBU",
        "outputId": "cd7784a5-92c5-4b4a-c260-4d66f141117a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': ['doc4'],\n",
              " 'title': ['Agentic Design Patterns Part 3: Tool Use'],\n",
              " 'source': ['https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io'],\n",
              " 'segment': ['There are four key AI agentic design patterns described by Andrew: \\\\n1. Reflection: The LLM examines its own work to come up with ways to improve it.\\\\n2. Tool Use: The LLM is given tools to help it gather information, take action, or process data.\\\\n3. Planning: The LLM comes up with and executes a multistep plan to achieve a goal.\\\\n4. Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.']}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4fkEQg65REq",
        "outputId": "e4b92645-d8c5-4bf4-83ef-a906f0bf04a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: doc4\n",
            "Title: Agentic Design Patterns Part 3: Tool Use\n",
            "Source: https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io\n",
            "Text Segment: There are four key AI agentic design patterns described by Andrew: \\n1. Reflection: The LLM examines its own work to come up with ways to improve it.\\n2. Tool Use: The LLM is given tools to help it gather information, take action, or process data.\\n3. Planning: The LLM comes up with and executes a multistep plan to achieve a goal.\\n4. Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for id, title, source, segment in zip(lookup_response[\"id\"], lookup_response[\"title\"], lookup_response[\"source\"], lookup_response[\"segment\"]):\n",
        "    print(f\"ID: {id}\\nTitle: {title}\\nSource: {source}\\nText Segment: {segment}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}